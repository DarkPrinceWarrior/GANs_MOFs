{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd2\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_linnerud\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from physlearn import Regressor\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные. Я их немножно подправил ещё до загрузки.\n",
    "df = pd.read_excel(\"data_00.xlsx\")\n",
    "\n",
    "# Уберём ненужные столбцы и пустые значения\n",
    "df = df.drop(columns=[\"Номер образца\", \"Адсорбент\"]).dropna()\n",
    "\n",
    "# Ещё один нюанс\n",
    "df = df[df[\"Sme, м2/г\"] != \"-\"]\n",
    "\n",
    "# Сменим тип данных у таблицы\n",
    "df[\"Sme, м2/г\"] = df[\"Sme, м2/г\"].astype(np.float64, copy=False)\n",
    "df[\"m (соли), г\"] = df[\"m (соли), г\"].astype(np.float64, copy=False)\n",
    "df[\"Vпр. (р-ля), мл\"] = df[\"Vпр. (р-ля), мл\"].astype(np.float64, copy=False)\n",
    "\n",
    "# У нас есть 3 категориальных признака, которых мы закодируем числами\n",
    "list_of_cats = [\"Металл\", \"Лиганд\", \"Растворитель\"]\n",
    "cat2id = {cat:{v:i for i, v in enumerate(df[cat].drop_duplicates().values)} for cat in list_of_cats}\n",
    "id2cat = {cat:{i:v for i, v in enumerate(df[cat].drop_duplicates().values)} for cat in list_of_cats}\n",
    "for cat in list_of_cats:\n",
    "    df[cat] = df[cat].apply(lambda x: cat2id[cat][x])\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем предсказывать 2 набора данных:\n",
    "# 1) Параметры МОК\n",
    "# 2) Параметры синтеза МОК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[Pipeline] ................ (step 1 of 2) Processing tr, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing reg, total=   0.0s\n",
      "[Pipeline] ................ (step 1 of 2) Processing tr, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing reg, total=   0.1s\n",
      "13.87\n"
     ]
    }
   ],
   "source": [
    "# Кусок кода взят отсюда: https://scikit-physlearn.readthedocs.io/en/latest/quick_start.html\n",
    "\n",
    "bunch = load_linnerud(as_frame=True)  # returns a Bunch instance\n",
    "X, y = df.iloc[:,:10], df.iloc[:,10:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "transformer_list = [('pca', PCA(n_components=1)),\n",
    "                    ('svd', TruncatedSVD(n_components=2))]\n",
    "union = FeatureUnion(transformer_list=transformer_list, n_jobs=-1)\n",
    "\n",
    "# Select a regressor, e.g., LGBMRegressor from LightGBM,\n",
    "# with a case-insensitive string.\n",
    "reg = Regressor(regressor_choice='lgbmregressor',\n",
    "                pipeline_transform=('tr', union),\n",
    "                scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Automatically build the pipeline with final estimator MultiOutputRegressor\n",
    "# from Sklearn, then exhaustively search over the (hyper)parameters.\n",
    "search_params = dict(reg__boosting_type=['gbdt', 'goss'],\n",
    "                     reg__n_estimators=[6, 8, 10, 20])\n",
    "reg.search(X_train, y_train, search_params=search_params,\n",
    "           search_method='gridsearchcv')\n",
    "\n",
    "# Generate predictions with the refit regressor, then\n",
    "# compute the average mean absolute error.\n",
    "y_pred = reg.fit(X_train, y_train).predict(X_test)\n",
    "score = reg.score(y_test, y_pred)\n",
    "print(round(score['mae'].mean(),2))\n",
    "# print(score['mae'].mean().round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2.965634</td>\n",
       "      <td>0.740797</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>6.981222</td>\n",
       "      <td>3.523975</td>\n",
       "      <td>75.053621</td>\n",
       "      <td>115.490869</td>\n",
       "      <td>364.656989</td>\n",
       "      <td>114.577164</td>\n",
       "      <td>6.893374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.756878</td>\n",
       "      <td>1.127329</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>1.435568</td>\n",
       "      <td>0.805628</td>\n",
       "      <td>31.810824</td>\n",
       "      <td>130.511127</td>\n",
       "      <td>163.634979</td>\n",
       "      <td>128.440354</td>\n",
       "      <td>1.214902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.885257</td>\n",
       "      <td>1.532047</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>2.232438</td>\n",
       "      <td>1.193876</td>\n",
       "      <td>33.055860</td>\n",
       "      <td>124.615397</td>\n",
       "      <td>149.844659</td>\n",
       "      <td>131.401259</td>\n",
       "      <td>2.522574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.331198</td>\n",
       "      <td>0.913095</td>\n",
       "      <td>0.109679</td>\n",
       "      <td>2.481090</td>\n",
       "      <td>1.684954</td>\n",
       "      <td>56.359493</td>\n",
       "      <td>127.587932</td>\n",
       "      <td>211.413984</td>\n",
       "      <td>126.211331</td>\n",
       "      <td>2.912554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.731507</td>\n",
       "      <td>1.152496</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>1.959854</td>\n",
       "      <td>1.368838</td>\n",
       "      <td>54.442805</td>\n",
       "      <td>133.507185</td>\n",
       "      <td>193.249978</td>\n",
       "      <td>135.264355</td>\n",
       "      <td>2.246213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4          5           6  \\\n",
       "236  2.965634  0.740797  0.066413  6.981222  3.523975  75.053621  115.490869   \n",
       "9    0.756878  1.127329  0.010475  1.435568  0.805628  31.810824  130.511127   \n",
       "57   1.885257  1.532047  0.009619  2.232438  1.193876  33.055860  124.615397   \n",
       "60   2.331198  0.913095  0.109679  2.481090  1.684954  56.359493  127.587932   \n",
       "25   1.731507  1.152496  0.014310  1.959854  1.368838  54.442805  133.507185   \n",
       "\n",
       "              7           8         9  \n",
       "236  364.656989  114.577164  6.893374  \n",
       "9    163.634979  128.440354  1.214902  \n",
       "57   149.844659  131.401259  2.522574  \n",
       "60   211.413984  126.211331  2.912554  \n",
       "25   193.249978  135.264355  2.246213  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскодируем наши категориальные признаки\n",
    "y_pred.columns = y.columns\n",
    "\n",
    "for cat in list_of_cats:\n",
    "    y_pred.loc[:,cat] = y_pred[cat].apply(lambda x: id2cat[cat][round(x)])\n",
    "\n",
    "# Сохраним результат\n",
    "y_pred.to_excel(\"baseline_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting CTGAN transformers for each column: 100%|██████████| 11/11 [00:01<00:00,  6.47it/s]\n",
      "Training CTGAN, epochs::  13%|█▎        | 64/500 [00:05<00:39, 11.05it/s]\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Do not support special JSON characters in feature name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[39m# for step in range(10):\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m gen_x, gen_y \u001b[39m=\u001b[39m GANGenerator(gen_x_times\u001b[39m=\u001b[39;49m\u001b[39m1.1\u001b[39;49m, cat_cols\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      9\u001b[0m            bot_filter_quantile\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, top_filter_quantile\u001b[39m=\u001b[39;49m\u001b[39m0.999\u001b[39;49m, \\\n\u001b[0;32m     10\u001b[0m               is_post_process\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     11\u001b[0m            adversarial_model_params\u001b[39m=\u001b[39;49m{\n\u001b[0;32m     12\u001b[0m                \u001b[39m\"\u001b[39;49m\u001b[39mmetrics\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mrmse\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_depth\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m2\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_bin\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m100\u001b[39;49m, \n\u001b[0;32m     13\u001b[0m                \u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0.02\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrandom_state\u001b[39;49m\u001b[39m\"\u001b[39;49m: \\\n\u001b[0;32m     14\u001b[0m                 \u001b[39m42\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mn_estimators\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m500\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m            }, pregeneration_frac\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, only_generated_data\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\\\n\u001b[0;32m     16\u001b[0m            gan_params \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m500\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpatience\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m25\u001b[39;49m, \\\n\u001b[0;32m     17\u001b[0m           \u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m : \u001b[39m500\u001b[39;49m,})\u001b[39m.\u001b[39;49mgenerate_data_pipe(X_train,pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49my_train\u001b[39m.\u001b[39;49miloc[:,\u001b[39m0\u001b[39;49m]) ,\\\n\u001b[0;32m     18\u001b[0m           X_test, deep_copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, only_adversarial\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \\\n\u001b[0;32m     19\u001b[0m           use_adversarial\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tabgan\\abc_sampler.py:77\u001b[0m, in \u001b[0;36mSampleData.generate_data_pipe\u001b[1;34m(self, train_df, target, test_df, deep_copy, only_adversarial, use_adversarial, only_generated_data)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m use_adversarial:\n\u001b[0;32m     76\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mApplying adversarial filtering\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m     new_train, new_target \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49madversarial_filtering(\n\u001b[0;32m     78\u001b[0m         new_train, new_target, test_df\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m     82\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTotal finishing, returning data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tabgan\\sampler.py:204\u001b[0m, in \u001b[0;36mSamplerOriginal.adversarial_filtering\u001b[1;34m(self, train_df, target, test_df)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(train_df, target, test_df)\n\u001b[0;32m    203\u001b[0m train_df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTEMP_TARGET] \u001b[39m=\u001b[39m target\n\u001b[1;32m--> 204\u001b[0m ad_model\u001b[39m.\u001b[39;49madversarial_test(test_df, train_df\u001b[39m.\u001b[39;49mdrop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mTEMP_TARGET, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m    206\u001b[0m train_df[\u001b[39m\"\u001b[39m\u001b[39mtest_similarity\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ad_model\u001b[39m.\u001b[39mtrained_model\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m    207\u001b[0m     train_df\u001b[39m.\u001b[39mdrop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTEMP_TARGET, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    208\u001b[0m )\n\u001b[0;32m    209\u001b[0m train_df\u001b[39m.\u001b[39msort_values(\u001b[39m\"\u001b[39m\u001b[39mtest_similarity\u001b[39m\u001b[39m\"\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tabgan\\adversarial_model.py:63\u001b[0m, in \u001b[0;36mAdversarialModel.adversarial_test\u001b[1;34m(self, left_df, right_df)\u001b[0m\n\u001b[0;32m     55\u001b[0m concated \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([left_df, right_df], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     56\u001b[0m lgb_model \u001b[39m=\u001b[39m Model(\n\u001b[0;32m     57\u001b[0m     cat_validation\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_validation,\n\u001b[0;32m     58\u001b[0m     encoders_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoders_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     model_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_params,\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m train_score, val_score, avg_num_trees \u001b[39m=\u001b[39m lgb_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     64\u001b[0m     concated\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mgt\u001b[39;49m\u001b[39m\"\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), concated[\u001b[39m\"\u001b[39;49m\u001b[39mgt\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtrain_score\u001b[39m\u001b[39m\"\u001b[39m: train_score,\n\u001b[0;32m     67\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mval_score\u001b[39m\u001b[39m\"\u001b[39m: val_score,\n\u001b[0;32m     68\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mavg_num_trees\u001b[39m\u001b[39m\"\u001b[39m: avg_num_trees}\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrained_model \u001b[39m=\u001b[39m lgb_model\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tabgan\\adversarial_model.py:162\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39m# fit model            \u001b[39;00m\n\u001b[0;32m    161\u001b[0m model \u001b[39m=\u001b[39m LGBMClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_params)\n\u001b[1;32m--> 162\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    163\u001b[0m     X_train,\n\u001b[0;32m    164\u001b[0m     y_train,\n\u001b[0;32m    165\u001b[0m     eval_set\u001b[39m=\u001b[39;49m[(X_train, y_train), (X_val, y_val)],\n\u001b[0;32m    166\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m    167\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_trees\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mbest_iteration_)\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_list\u001b[39m.\u001b[39mappend(model)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mtransform(valid_y))\n\u001b[1;32m--> 967\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, _y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score, eval_set\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    968\u001b[0m             eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m    969\u001b[0m             eval_class_weight\u001b[39m=\u001b[39;49meval_class_weight, eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[0;32m    970\u001b[0m             eval_metric\u001b[39m=\u001b[39;49meval_metric, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m    971\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[0;32m    972\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[0;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\basic.py:1573\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWrong predictor type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(predictor)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1572\u001b[0m \u001b[39m# set feature names\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_feature_name(feature_name)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\basic.py:2142\u001b[0m, in \u001b[0;36mDataset.set_feature_name\u001b[1;34m(self, feature_name)\u001b[0m\n\u001b[0;32m   2140\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of feature_name(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(feature_name)\u001b[39m}\u001b[39;00m\u001b[39m) and num_feature(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_feature()\u001b[39m}\u001b[39;00m\u001b[39m) don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2141\u001b[0m     c_feature_name \u001b[39m=\u001b[39m [c_str(name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m feature_name]\n\u001b[1;32m-> 2142\u001b[0m     _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_DatasetSetFeatureNames(\n\u001b[0;32m   2143\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   2144\u001b[0m         c_array(ctypes\u001b[39m.\u001b[39;49mc_char_p, c_feature_name),\n\u001b[0;32m   2145\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(\u001b[39mlen\u001b[39;49m(feature_name))))\n\u001b[0;32m   2146\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\lightgbm\\basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Do not support special JSON characters in feature name."
     ]
    }
   ],
   "source": [
    "from tabgan.sampler import GANGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for step in range(10):\n",
    "\n",
    "gen_x, gen_y = GANGenerator(gen_x_times=1.1, cat_cols=None,\n",
    "           bot_filter_quantile=0.001, top_filter_quantile=0.999, \\\n",
    "              is_post_process=True,\n",
    "           adversarial_model_params={\n",
    "               \"metrics\": \"rmse\", \"max_depth\": 2, \"max_bin\": 100, \n",
    "               \"learning_rate\": 0.02, \"random_state\": \\\n",
    "                42, \"n_estimators\": 500,\n",
    "           }, pregeneration_frac=2, only_generated_data=False,\\\n",
    "           gan_params = {\"batch_size\": 500, \"patience\": 25, \\\n",
    "          \"epochs\" : 500,}).generate_data_pipe(X_train,pd.DataFrame(data=y_train.iloc[:,0]) ,\\\n",
    "          X_test, deep_copy=True, only_adversarial=False, \\\n",
    "          use_adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      \n",
       "119  1\n",
       "266  4\n",
       "252  5\n",
       "212  0\n",
       "137  1\n",
       "..  ..\n",
       "195  4\n",
       "71   1\n",
       "106  4\n",
       "278  4\n",
       "102  4\n",
       "\n",
       "[234 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=y_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "score = np.sqrt(metrics.mean_squared_error(y_pred.values,gen_y.values))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a926afa313b26ae1264fdcf81c726a97e69f6ba2ba780f6aa901948710f8d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
